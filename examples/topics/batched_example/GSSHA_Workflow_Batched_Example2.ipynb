{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second of a series that shows how [GSSHA_Workflow.ipynb](../GSSHA_Workflow.ipynb) can be parameterized at the command line that builds on [GSSHA_Workflow_Batched_Example1](GSSHA_Workflow_Batched_Example1.ipynb). This notebook uses the same principles as the first example but makes the interface more user friendly and Windows compatible.\n",
    "\n",
    "As in the first example, the two parameters we choose to expose are ``rain_intensity`` and ``rain_duration``. As before, the notebook is configured to use these parameters in three steps.\n",
    "\n",
    "1. <a href=\"#Declare_nbparams\">Declare the command line parameters</a>\n",
    "2. <a href=\"#Display_nbparams\">Display the notebook parameter widgets</a>\n",
    "3. <a href=\"#Apply_nbparams\">Apply notebook parameters and display</a>\n",
    "\n",
    "Only the first step <a href=\"#Declare_nbparams\">Declare the command line parameters</a> is different from the first example; the second step is identical and the third step is only different by a trivial variable name change.\n",
    "\n",
    "The main improvement presented here is in the interface used to set parameters at the command line:\n",
    "\n",
    "```bash\n",
    "param -cmd 'jupyter nbconvert --execute GSSHA_Workflow_Batched_Example2.ipynb' -p rain_intensity=25 -p rain_duration=3600\n",
    "```\n",
    "\n",
    "As in the first example, an arbitrary command can be executed but in this instance a nicer syntax is used to specify the desired parameters. The ``param`` command generates the appropriate environment variable and makes it available to the execution context in a way that is cross platform, allowing this utility to be used on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import param\n",
    "import parambokeh\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import quest\n",
    "import earthsim.gssha as esgssha\n",
    "import earthsim.gssha.model as models\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from earthsim.gssha import download_data, get_file_from_quest\n",
    "from earthsim.gssha.model import UniformRoughness, CreateGSSHAModel\n",
    "from holoviews.streams import PolyEdit, BoxEdit, PointDraw, CDSStream\n",
    "from holoviews.operation.datashader import regrid, shade\n",
    "from earthsim.io import save_shapefile, open_gssha, get_ccrs\n",
    "\n",
    "regrid.aggregator = 'max'\n",
    "\n",
    "hv.extension('bokeh')\n",
    "%output holomap='scrubber' fps=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r ./vicksburg_south/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the command line parameters <a id=\"Declare_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous example, the  ``rain_intensity`` and ``rain_duration`` of ``Simulation`` are exposed. The change here is that instead of explicitly defining the ``NotebookParams`` class, a helper function called ``global_params`` is used instead.\n",
    "\n",
    "This utility makes the definition of notebook parameters more concise and readable. In addition to parameter objects, you can simply use literals for quick parameter definitions. For instance, the literal ``5`` is promoted to a ``param.Integer``, the literal ``6.2`` is promoted to a ``param.Number``, ``'example'`` is promoted to a ``param.String`` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthsim import parameters\n",
    "nbparams = parameters(\n",
    "    rain_intensity = param.Number(default=24, bounds=(0,None), softbounds=(0,75)),\n",
    "    rain_duration = 60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the literal specification is shorter and easier to read but is lacking documentation and numeric bounds declarations. This may also result in less user-friendly widgets:  ``rain_duration`` is displayed with a text box in the next code cell instead of a slider. Using literals to define notebook parameters is most appropriate for generating static HTML reports from the command line where the widgets won't be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the notebook parameter widgets  <a id=\"Display_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step makes the notebook parameters available to change at the start of the notebook, parameterizing the interactive workflow. In addition, using ``initializer=parambokeh.JSONInit()`` allows these parameters to be set from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(nbparams, initializer=parambokeh.JSONInit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creator = esgssha.CreateGSSHAModel(name='Vicksburg South Model Creator',\n",
    "                                        mask_shapefile='../../data/vicksburg_watershed/watershed_boundary.shp',\n",
    "                                        grid_cell_size=90)\n",
    "parambokeh.Widgets(model_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameters of the ``roughness`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_creator.roughness = UniformRoughness()\n",
    "parambokeh.Widgets(model_creator.roughness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounds to compute watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows drawing a bounding box and adding points to serve as input to compute a watershed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Polygons [width=900 height=500] (fill_alpha=0 line_color='black')\n",
    "%%opts Points (size=10 color='red')\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png',\n",
    "                crs=ccrs.PlateCarree(), extents=(-91, 32.2, -90.8, 32.4))\n",
    "box_poly = hv.Polygons([])\n",
    "points = hv.Points([])\n",
    "box_stream = BoxEdit(source=box_poly)\n",
    "point_stream = PointDraw(source=points)\n",
    "tiles * box_poly * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if box_stream.element:\n",
    "    element = gv.operation.project(box_stream.element, projection=ccrs.PlateCarree())\n",
    "    xs, ys = element.array().T\n",
    "    bounds = (xs[0], ys[1], xs[2], ys[0])\n",
    "    print(\"BOUNDS\", bounds)\n",
    "    \n",
    "if point_stream.element:\n",
    "    projected = gv.operation.project(point_stream.element, projection=ccrs.PlateCarree())\n",
    "    print(\"COORDINATE:\", projected.iloc[0]['x'][0], projected.iloc[0]['y'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and edit shapefile\n",
    "\n",
    "The plot below allows editing the shapefile using a set of tools. The controls for editing are as follows:\n",
    "    \n",
    "* Double-clicking the polygon displays the vertices\n",
    "* After double-clicking the point tool is selected and vertices can be dragged around\n",
    "* By tapping on a vertex it can be selected, tapping in a new location while a single point is selected inserts a new vertex\n",
    "* Multiple points can be selected by holding shift and then tapping or using the box_select tool\n",
    "* Once multiple vertices are selected they can be deleted by selecting the point editing tool and pressing ``backspace``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=900 height=500 tools=['box_select']] (alpha=0.5)\n",
    "mask_shape = gv.Shape.from_shapefile(model_creator.mask_shapefile).last\n",
    "tiles = gv.WMTS('http://c.tile.openstreetmap.org/{Z}/{X}/{Y}.png')\n",
    "vertex_stream = PolyEdit(source=mask_shape)\n",
    "tiles * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any edits were made to the polygon in the plot above we save the ``watershed_boundary.shp`` back out and redisplay it to confirm our edits were applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Shape [width=600 height=400] (alpha=0.5)\n",
    "if vertex_stream.data:\n",
    "    edited_shape_fname = '../vicksburg_watershed_edited/watershed_boundary.shp'\n",
    "    dir_name = os.path.dirname(edited_shape_fname)\n",
    "    if not os.path.isdir(dir_name): os.makedirs(dir_name)\n",
    "    save_shapefile(vertex_stream.data, edited_shape_fname, model_creator.mask_shapefile)\n",
    "    model_creator.mask_shapefile = edited_shape_fname\n",
    "    mask_shape = gv.Shape.from_shapefile(edited_shape_fname).last\n",
    "mask_shape = mask_shape.opts() # Clear options\n",
    "mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = esgssha.Simulation(name='Vicksburg South Simulation', simulation_duration=60*60,\n",
    "                          rain_duration=30*60, model_creator=model_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply notebook parameters and display<a id=\"Apply_nbparams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the point at which the notebook parameters hook into the workflow. In this example, the two chosen parameters ``rain_duration`` and ``rain_intensity`` are simply set on ``sim``. In more complex examples, you may decide to compute the parameters set in the workflow as a function of the availabel notebook parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.rain_duration = nbparams.rain_duration \n",
    "sim.rain_intensity = nbparams.rain_intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Note that the above code demonstrates how to collect user input, but it has not yet been connected to the remaining workflow, which uses code-based specification for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim.model_creator.project_name not in quest.api.get_collections():\n",
    "    quest.api.new_collection(sim.model_creator.project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parambokeh.Widgets(sim.model_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary workaround until workflow cleanup/parameterization is done\n",
    "if sim.model_creator.project_name == 'test_philippines_small':\n",
    "    sim.model_creator.roughness = models.GriddedRoughnessTable(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_to_roughness_table='../philippines_small/land_cover_glcf_modis.txt')\n",
    "else:    \n",
    "    sim.model_creator.roughness = models.GriddedRoughnessID(\n",
    "        land_use_grid=get_file_from_quest(sim.model_creator.project_name, sim.land_use_service, 'landuse', sim.model_creator.mask_shapefile),\n",
    "        land_use_grid_id=sim.land_use_grid_id)\n",
    "\n",
    "sim.model_creator.elevation_grid_path = get_file_from_quest(sim.model_creator.project_name, sim.elevation_service, 'elevation', sim.model_creator.mask_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sim.model_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add card for max depth\n",
    "model.project_manager.setCard('FLOOD_GRID',\n",
    "                              '{0}.fgd'.format(sim.model_creator.project_name),\n",
    "                              add_quotes=True)\n",
    "# Add time-based depth grids to simulation\n",
    "\"\"\"\n",
    "See: http://www.gsshawiki.com/Project_File:Output_Files_%E2%80%93_Required\n",
    "\n",
    "Filename or folder to output MAP_TYPE maps of overland flow depth (m) \n",
    "every MAP_FREQ minutes. If MAP_TYPE=0, then [value] is a folder name \n",
    "and output files are called \"value\\depth.####.asc\" **\n",
    "\"\"\"\n",
    "\n",
    "model.project_manager.setCard('DEPTH', '.', add_quotes=True)\n",
    "model.project_manager.setCard('MAP_FREQ', '1')\n",
    "\n",
    "# add event for simulation (optional)\n",
    "\"\"\"\n",
    "model.set_event(simulation_start=sim.simulation_start,\n",
    "                simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                rain_intensity=sim.rain_intensity,\n",
    "                rain_duration=timedelta(seconds=sim.rain_duration))\n",
    "\"\"\"\n",
    "# write to disk\n",
    "model.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load inputs to the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = sim.model_creator.project_name\n",
    "CRS = get_ccrs(os.path.join(name, name+'_prj.pro'))\n",
    "\n",
    "roughness_arr = open_gssha(os.path.join(name,'roughness.idx'))\n",
    "msk_arr = open_gssha(os.path.join(name, name+'.msk'))\n",
    "ele_arr = open_gssha(os.path.join(name, name+'.ele'))\n",
    "\n",
    "roughness = gv.Image(roughness_arr, crs=CRS, label='roughness.idx')\n",
    "mask = gv.Image(msk_arr, crs=CRS, label='vicksburg_south.msk')\n",
    "ele  = gv.Image(ele_arr, crs=CRS, label='vicksburg_south.ele')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapefile vs. Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(mask) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(ele) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles * regrid(roughness) * mask_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsshapy.modeling import GSSHAFramework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how does the info here relate to that set earlier?\n",
    "\n",
    "# TODO: understand comment below\n",
    "# assuming notebook is run from examples folder\n",
    "project_path = os.path.join(sim.model_creator.project_base_directory, sim.model_creator.project_name)\n",
    "gr = GSSHAFramework(\"gssha\",\n",
    "                    project_path,\n",
    "                    \"{0}.prj\".format(sim.model_creator.project_name),\n",
    "                    gssha_simulation_start=sim.simulation_start,\n",
    "                    gssha_simulation_duration=timedelta(seconds=sim.simulation_duration),\n",
    "                    # load_simulation_datetime=True,  # use this if already set datetime params in project file\n",
    "                   )\n",
    "\n",
    "# http://www.gsshawiki.com/Model_Construction:Defining_a_uniform_precipitation_event\n",
    "gr.event_manager.add_uniform_precip_event(sim.rain_intensity, \n",
    "                                          timedelta(seconds=sim.rain_duration))\n",
    "\n",
    "gssha_event_directory = gr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize depths over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_nc = os.path.join(gssha_event_directory, 'depths.nc')\n",
    "if not os.path.isfile(depth_nc):\n",
    "    # Load depth data files\n",
    "    depth_map = hv.HoloMap(kdims=['Minute'])\n",
    "    for fname in glob.glob(os.path.join(gssha_event_directory, 'depth.*.asc')):\n",
    "        depth_arr = open_gssha(fname)\n",
    "        minute = int(fname.split('.')[-2])\n",
    "        # NOTE: Due to precision issues not all empty cells match the NaN value properly, fix later\n",
    "        depth_arr.data[depth_arr.data==depth_arr.data[0,0]] = np.NaN\n",
    "        depth_map[minute] = hv.Image(depth_arr)\n",
    "\n",
    "    # Convert data to an xarray and save as NetCDF\n",
    "    arrays = []\n",
    "    for minute, img in depth_map.items():\n",
    "        ds = hv.Dataset(img)\n",
    "        arr = ds.data.z.assign_coords(minute=minute)\n",
    "        arrays.append(arr)\n",
    "    depths = xr.concat(arrays, 'minute')\n",
    "    depths.to_netcdf(depth_nc)\n",
    "else:\n",
    "    depths = xr.open_dataset(depth_nc)\n",
    "\n",
    "depth_ds = hv.Dataset(depths)\n",
    "depth_ds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Dataset of depths we can convert it to a series of Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400 logz=True xaxis=None yaxis=None] (cmap='viridis') Histogram {+framewise}\n",
    "regrid(depth_ds.to(hv.Image, ['x', 'y'])).redim.range(z=(0, 0.04)).hist(bin_range=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also lay out the plots over time to allow for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=300 height=300 logz=True xaxis=None yaxis=None] (cmap='viridis')\n",
    "regrid(depth_ds.select(minute=range(10, 70, 10)).to(hv.Image, ['x', 'y']).redim.range(z=(0, 0.04))).layout().cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flood Grid Depth\n",
    "\n",
    "(Maximum flood depth over the course of the simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=400] (cmap='viridis')\n",
    "fgd_arr = open_gssha(os.path.join(gssha_event_directory,'{0}.fgd'.format(sim.model_creator.project_name)))\n",
    "fgd = gv.Image(fgd_arr, crs=CRS, label='vicksburg_south.fgd').redim.range(z=(0, 0.04))\n",
    "regrid(fgd, streams=[hv.streams.RangeXY]).redim.range(z=(0, 0.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the simulation speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Spikes [width=600]\n",
    "times = np.array([os.path.getmtime(f) for f in glob.glob(os.path.join(gssha_event_directory, 'depth*.asc'))] )\n",
    "minutes = (times-times[0])/60\n",
    "hv.Spikes(minutes, kdims=['Real Time (minutes)'], label='Time elapsed for each minute of simulation time') +\\\n",
    "hv.Curve(np.diff(minutes), kdims=['Simulation Time (min)'], vdims=[('runtime', 'Runtime per minute simulation time')]).redim.range(runtime=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here if the \"spikes\" are regularly spaced, simulation time is regularly scaled with real time, and so you should be able read out the approximate time to expect per unit of simulation time."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
